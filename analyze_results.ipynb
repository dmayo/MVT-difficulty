{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import redis\n",
    "from itertools import chain\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']#['retina']\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment video data from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'example_experiment'\n",
    "video_data_path = f\"experiment/public/experiment_data/video_data_{experiment_name}.json\"\n",
    "with open(video_data_path) as f:\n",
    "    video_data = json.load(f)\n",
    "\n",
    "for v in video_data:\n",
    "    v[\"objectnet\"] = True if v['image'][0] != 'I' else False\n",
    "\n",
    "video_data = pd.DataFrame(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_num = {}\n",
    "for video in tqdm(video_data['video'].unique()):\n",
    "    video_num = video_data[video_data['video'] == video].index[0]\n",
    "    video_to_num[video] = video_num\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test subject responses from redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = os.environ\n",
    "EXPERIMENT_HOST = environment.get(\"EXPERIMENT_HOST\")\n",
    "EXPERIMENT_PORT = environment.get(\"EXPERIMENT_PORT\")\n",
    "REDIS_HOST = environment.get(\"REDIS_HOST\")\n",
    "REDIS_PORT = environment.get(\"REDIS_PORT\")\n",
    "REDIS_DB = environment.get(\"REDIS_DB\")\n",
    "REDIS_PASSWORD = environment.get(\"REDIS_PASSWORD\")\n",
    "NUM_IMAGES_PER_TASK = environment.get(\"NUM_IMAGES_PER_TASK\")\n",
    "NUM_VIDEO_LISTS_PER_LINK = environment.get(\"NUM_VIDEO_LISTS_PER_LINK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_db = True\n",
    "all_workers = set()\n",
    "if load_from_db:\n",
    "    r = redis.Redis(host=REDIS_HOST,\n",
    "                port=REDIS_PORT,\n",
    "                password=REDIS_PASSWORD,\n",
    "                charset=\"utf-8\",\n",
    "                decode_responses=True, \n",
    "                db=REDIS_DB)\n",
    "    link_ids = r.smembers(experiment_name)\n",
    "    video_responses = {}\n",
    "    responses = {}\n",
    "    worker_ids = {id: [] for id in link_ids}\n",
    "    worker_to_link = {}\n",
    "    for key in r.keys():\n",
    "        if key.endswith(':responses'):\n",
    "            all_workers.add(key[19:-10])\n",
    "            if key[:8] not in link_ids:\n",
    "                continue\n",
    "            worker_ids[key[:8]].append(key[19:-10])\n",
    "            if not worker_to_link.get(key[19:-10]):\n",
    "                worker_to_link[key[19:-10]] = []\n",
    "            worker_to_link[key[19:-10]].append(key[:8])\n",
    "    \n",
    "    for worker in worker_to_link:\n",
    "        for link in worker_to_link[worker]:\n",
    "            r.sadd(worker + ':links', link)\n",
    "        \n",
    "    all_assignments = set()\n",
    "    for link_id in link_ids:\n",
    "       \n",
    "        for worker_id in worker_ids[link_id]:\n",
    "            if not responses.get(worker_id):\n",
    "                responses[worker_id] = []\n",
    "            response = r.smembers(link_id+\":worker_id:\" + worker_id + \":responses\")\n",
    "            trials = []\n",
    "            trial = list(response)[0]\n",
    "            assignment_id = r.hgetall(link_id+\":worker_id:\" + worker_id +\":response:\"+trial).get('assignment_id')\n",
    "\n",
    "            if len(response) > 0: NUM_IMAGES_PER_TASK:\n",
    "                for trial in list(response):\n",
    "                    trials.append(r.hgetall(link_id+\":worker_id:\" + worker_id +\":response:\"+trial))\n",
    "            all_assignments.add(assignment_id)\n",
    "\n",
    "            responses[worker_id].extend(trials)\n",
    "        \n",
    "    response_data = pd.DataFrame(list(chain.from_iterable(responses.values())))\n",
    "    response_data['video_num'] = response_data['video_num'].map(video_to_num)\n",
    "    response_data['response_time'] = response_data['response_time'].astype(int)/1000\n",
    "    del response_data['video']\n",
    "    response_data = response_data.set_index('video_num').join(video_data)\n",
    "    \n",
    "    \n",
    "# maintain a list of all workers\n",
    "with open(f'worker_ids_{experiment_name}.json', 'w') as f:\n",
    "    json.dump(list(all_workers), f)\n",
    "    print(len(all_workers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data.trial_num = response_data.trial_num.astype(int)\n",
    "response_data = response_data.sort_values(\"trial_num\")\n",
    "response_data.dropna(how='any', inplace=True)\n",
    "        \n",
    "        \n",
    "# convert frame counts to ms\n",
    "def get_adjusted_duration(timing):\n",
    "    return round(timing / 60 * 1000)\n",
    "response_data['image_duration'] = [get_adjusted_duration(a) for a in response_data['image_duration']]\n",
    "\n",
    "# mark correctness of responses\n",
    "response_data = response_data.fillna(0)\n",
    "response_data['is_correct'] = [(1 if a==True else 0) for a in (response_data['response']==response_data['label'])]\n",
    "                 \n",
    "response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finds list of workers who have less than 60% accuracy at 10s image duration. You should strongly consider ignoring\n",
    "these results and reposting the assignments for replacement by other workers. We do not necessarily recommend rejecting \n",
    "workers assignments on MTurk because that can get complicated to do fairly, but we have set up the backend such that you\n",
    "can block these workers from doing more tasks and mark their assignments for replacement.\n",
    "\"\"\"\n",
    "worker_accuracies = response_data.groupby(['worker_id', 'image_duration']).mean()['is_correct']\n",
    "workers_to_block = list(set([x[0] for x in worker_accuracies[worker_accuracies < 0.6].index if x[1] == 10_000]))\n",
    "print('Workers with low 10s accuracy', len(workers_to_block))\n",
    "\n",
    "# adds workers to blocked list\n",
    "for worker in workers_to_block:\n",
    "    r.sadd('blocked_worker_ids', worker)\n",
    "    \n",
    "    \n",
    "# marks all assignments completed by blocked workers for replacement by new workers\n",
    "assignments_to_replace = response_data[response_data['worker_id'].isin(workers_to_block)]['assignment_id'].unique()\n",
    "for assignment in assignments_to_replace:\n",
    "    r.sadd('assignments_to_replace', assignment)\n",
    "    \n",
    "    \n",
    "response_data = response_data[~response_data['worker_id'].isin(workers_to_block)]\n",
    "response_data.to_csv(f'{experiment_name}_results.csv') # save experiment to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keep track of how many unique workers have completed tasks for each link. \n",
    "This should give you a good idea how close you are to getting the whole\n",
    "complement of responses and which links you need to repost with how\n",
    "many new assignments.\n",
    "\"\"\"\n",
    "link_counts = response_data.groupby(['link_id']).nunique()['worker_id']\n",
    "link_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To get more explicit information about which results are missing, take a \n",
    "look at how many times each image has been seen at each timing. Images\n",
    "with fewer responses at a given timing than they should have indicate\n",
    "assignments that are yet to be completed or need replacement.\n",
    "\"\"\"\n",
    "num_workers_per_image_per_duration = #TODO\n",
    "exp_image_count = response_data.groupby([\"image_duration\", \"image\"]).count()[\"trial_num\"] #TODO\n",
    "need_more_responses = list(set([x[1] for x in exp_image_count[exp_image_count < num_workers_per_image_per_duration].index]))\n",
    "need_more_responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
